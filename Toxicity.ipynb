{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:22:27.523781600Z",
     "start_time": "2023-12-01T23:22:11.068999600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dell 5590 i7\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:22:28.645981500Z",
     "start_time": "2023-12-01T23:22:27.522784500Z"
    }
   },
   "id": "bc6a8ecea8b1a2a4"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                      id                                       comment_text  \\\n0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n...                  ...                                                ...   \n159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n\n        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n0           0             0        0       0       0              0  \n1           0             0        0       0       0              0  \n2           0             0        0       0       0              0  \n3           0             0        0       0       0              0  \n4           0             0        0       0       0              0  \n...       ...           ...      ...     ...     ...            ...  \n159566      0             0        0       0       0              0  \n159567      0             0        0       0       0              0  \n159568      0             0        0       0       0              0  \n159569      0             0        0       0       0              0  \n159570      0             0        0       0       0              0  \n\n[159571 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>159566</th>\n      <td>ffe987279560d7ff</td>\n      <td>\":::::And for the second time of asking, when ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159567</th>\n      <td>ffea4adeee384e90</td>\n      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159568</th>\n      <td>ffee36eab5c267c9</td>\n      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159569</th>\n      <td>fff125370e4aaaf3</td>\n      <td>And it looks like it was actually you who put ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159570</th>\n      <td>fff46fc426af1f9a</td>\n      <td>\"\\nAnd ... I really don't think you understand...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>159571 rows Ã— 8 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:22:28.708934600Z",
     "start_time": "2023-12-01T23:22:28.664539400Z"
    }
   },
   "id": "81c791ee46612c81"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n       'insult', 'identity_hate'],\n      dtype='object')"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:22:28.758609400Z",
     "start_time": "2023-12-01T23:22:28.698636400Z"
    }
   },
   "id": "6f735cdd124d9dc7"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic:\n",
      "toxic\n",
      "0    144277\n",
      "1     15294\n",
      "Name: count, dtype: int64\n",
      "\n",
      "severe_toxic:\n",
      "severe_toxic\n",
      "0    157976\n",
      "1      1595\n",
      "Name: count, dtype: int64\n",
      "\n",
      "obscene:\n",
      "obscene\n",
      "0    151122\n",
      "1      8449\n",
      "Name: count, dtype: int64\n",
      "\n",
      "threat:\n",
      "threat\n",
      "0    159093\n",
      "1       478\n",
      "Name: count, dtype: int64\n",
      "\n",
      "insult:\n",
      "insult\n",
      "0    151694\n",
      "1      7877\n",
      "Name: count, dtype: int64\n",
      "\n",
      "identity_hate:\n",
      "identity_hate\n",
      "0    158166\n",
      "1      1405\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "columns = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "       'insult', 'identity_hate']\n",
    "\n",
    "# Loop through the list of columns\n",
    "for column in columns:\n",
    "    counts = data[column].value_counts()\n",
    "    print(column + ':')\n",
    "    print(counts)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:22:28.838975400Z",
     "start_time": "2023-12-01T23:22:28.714919100Z"
    }
   },
   "id": "dc7a1a53884047c4"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Count per Column:\n",
      "id               0\n",
      "comment_text     0\n",
      "toxic            0\n",
      "severe_toxic     0\n",
      "obscene          0\n",
      "threat           0\n",
      "insult           0\n",
      "identity_hate    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = data.isnull().sum()\n",
    "\n",
    "print(\"Missing Values Count per Column:\")\n",
    "print(missing_values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:22:28.993170600Z",
     "start_time": "2023-12-01T23:22:28.761604200Z"
    }
   },
   "id": "8fd36a332518c1"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "data['comment_text'] = data['comment_text'].apply(lambda x: x.lower())  # Lowercase text\n",
    "data['comment_text'] = data['comment_text'].str.replace('[^\\w\\s]', '', regex=False)  # Remove punctuation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:22:29.161122400Z",
     "start_time": "2023-12-01T23:22:28.806721200Z"
    }
   },
   "id": "aeb350407ba9807b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the dataset: 470340\n"
     ]
    }
   ],
   "source": [
    "num_words_in_dataset = data['comment_text'].str.split().explode().nunique()\n",
    "\n",
    "print(f\"Number of unique words in the dataset: {num_words_in_dataset}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:22:31.978049600Z",
     "start_time": "2023-12-01T23:22:29.183379500Z"
    }
   },
   "id": "2b822db5a1274cc"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "data = data.drop('id', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:22:32.049724700Z",
     "start_time": "2023-12-01T23:22:31.979552900Z"
    }
   },
   "id": "417b599f28ffe87b"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:22:34.593370900Z",
     "start_time": "2023-12-01T23:22:32.012581900Z"
    }
   },
   "id": "31719f43829644e6"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Train the Word2Vec model\n",
    "corpus = [doc.split() for doc in data['comment_text']]\n",
    "Word2Vecmodel = Word2Vec(sentences=corpus, vector_size=100, window=10, min_count=3, workers=6)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:23:12.997976600Z",
     "start_time": "2023-12-01T23:22:34.595364500Z"
    }
   },
   "id": "643545784654311"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Tokenize text data\n",
    "tokenizer = Tokenizer(num_words=num_words_in_dataset, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(data['comment_text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:23:21.957104300Z",
     "start_time": "2023-12-01T23:23:12.997976600Z"
    }
   },
   "id": "6431eeafa718397e"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:23:22.368565600Z",
     "start_time": "2023-12-01T23:23:21.959070300Z"
    }
   },
   "id": "d447f31d69a7df70"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Split set\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:23:22.416792200Z",
     "start_time": "2023-12-01T23:23:22.372581600Z"
    }
   },
   "id": "b12d32f637886548"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Convert text to sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_data['comment_text'])\n",
    "val_sequences = tokenizer.texts_to_sequences(val_data['comment_text'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['comment_text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:23:28.762195200Z",
     "start_time": "2023-12-01T23:23:22.428772600Z"
    }
   },
   "id": "6b8a496851be451"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "train_padded = pad_sequences(train_sequences, maxlen=256, truncating='post', padding='post')\n",
    "val_padded = pad_sequences(val_sequences, maxlen=256, truncating='post', padding='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=256, truncating='post', padding='post')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:23:29.588472500Z",
     "start_time": "2023-12-01T23:23:28.782542300Z"
    }
   },
   "id": "cd59b84ed30dd0de"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Define the vocabulary size and embedding matrix\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((vocab_size, 100))  \n",
    "for word, i in word_index.items():\n",
    "    if word in Word2Vecmodel.wv.key_to_index:\n",
    "        embedding_matrix[i] = Word2Vecmodel.wv[word]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:23:29.766972100Z",
     "start_time": "2023-12-01T23:23:29.592493900Z"
    }
   },
   "id": "2152c5fe1e68791"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:23:29.779983Z",
     "start_time": "2023-12-01T23:23:29.769924300Z"
    }
   },
   "id": "cb02776a17e26b91"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dell 5590 i7\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n"
     ]
    }
   ],
   "source": [
    "# Define the model \n",
    "input_layer = Input(shape=(256,))  \n",
    "\n",
    "# Embedding layer\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=100, weights=[embedding_matrix], input_length=256, trainable=False)(input_layer)\n",
    "\n",
    "# Bidirectional LSTM layer \n",
    "lstm_layer = Bidirectional(LSTM(128, return_sequences=True))(embedding_layer)\n",
    "lstm_layer = Bidirectional(LSTM(64))(lstm_layer)\n",
    "\n",
    "output_layers = []\n",
    "for column in columns:\n",
    "    dense_layer = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(lstm_layer)\n",
    "    batch_norm_layer = BatchNormalization()(dense_layer)\n",
    "    activation_layer = Activation('relu')(batch_norm_layer)\n",
    "    dropout_layer = Dropout(0.2)(activation_layer)\n",
    "    output = Dense(6, activation='sigmoid')(dropout_layer)  \n",
    "    output_layers.append(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:23:31.768919800Z",
     "start_time": "2023-12-01T23:23:29.779983Z"
    }
   },
   "id": "6efc12621b5b2b6b"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=output_layers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:23:31.811126400Z",
     "start_time": "2023-12-01T23:23:31.769944Z"
    }
   },
   "id": "a270a7c7befa54bd"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0005), \n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:23:31.828730800Z",
     "start_time": "2023-12-01T23:23:31.798536400Z"
    }
   },
   "id": "79b35e7285ad36df"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 256)]                0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 256, 100)             2103390   ['input_1[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 256, 256)             234496    ['embedding[0][0]']           \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirecti  (None, 128)                  164352    ['bidirectional[0][0]']       \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  16512     ['bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 128)                  16512     ['bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 128)                  16512     ['bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 128)                  16512     ['bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 128)                  16512     ['bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 128)                  16512     ['bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 128)                  512       ['dense[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 128)                  512       ['dense_2[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 128)                  512       ['dense_4[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 128)                  512       ['dense_6[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 128)                  512       ['dense_8[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 128)                  512       ['dense_10[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 128)                  0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 128)                  0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, 128)                  0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 128)                  0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 128)                  0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 128)                  0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 128)                  0         ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 128)                  0         ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 128)                  0         ['activation_2[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 128)                  0         ['activation_3[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 128)                  0         ['activation_4[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 128)                  0         ['activation_5[0][0]']        \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 6)                    774       ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 6)                    774       ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 6)                    774       ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 6)                    774       ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 6)                    774       ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 6)                    774       ['dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21539536 (82.17 MB)\n",
      "Trainable params: 504100 (1.92 MB)\n",
      "Non-trainable params: 21035436 (80.24 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:23:32.013467800Z",
     "start_time": "2023-12-01T23:23:31.831241900Z"
    }
   },
   "id": "6b32f66a0a734114"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "columns = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "       'insult', 'identity_hate']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T23:23:32.042808100Z",
     "start_time": "2023-12-01T23:23:31.928575500Z"
    }
   },
   "id": "a2f23a3b75635896"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:From C:\\Users\\dell 5590 i7\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "WARNING:tensorflow:From C:\\Users\\dell 5590 i7\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "3990/3990 [==============================] - 1776s 442ms/step - loss: 0.7204 - dense_1_loss: 0.0721 - dense_3_loss: 0.0691 - dense_5_loss: 0.0735 - dense_7_loss: 0.0742 - dense_9_loss: 0.0710 - dense_11_loss: 0.0726 - dense_1_accuracy: 0.8799 - dense_3_accuracy: 0.8912 - dense_5_accuracy: 0.8130 - dense_7_accuracy: 0.8670 - dense_9_accuracy: 0.8582 - dense_11_accuracy: 0.8081 - val_loss: 0.3407 - val_dense_1_loss: 0.0538 - val_dense_3_loss: 0.0533 - val_dense_5_loss: 0.0550 - val_dense_7_loss: 0.0548 - val_dense_9_loss: 0.0538 - val_dense_11_loss: 0.0536 - val_dense_1_accuracy: 0.9930 - val_dense_3_accuracy: 0.9930 - val_dense_5_accuracy: 0.9930 - val_dense_7_accuracy: 0.9930 - val_dense_9_accuracy: 0.9930 - val_dense_11_accuracy: 0.9930\n",
      "Epoch 2/15\n",
      "3990/3990 [==============================] - 1759s 441ms/step - loss: 0.3282 - dense_1_loss: 0.0521 - dense_3_loss: 0.0523 - dense_5_loss: 0.0523 - dense_7_loss: 0.0522 - dense_9_loss: 0.0521 - dense_11_loss: 0.0522 - dense_1_accuracy: 0.9825 - dense_3_accuracy: 0.9861 - dense_5_accuracy: 0.9724 - dense_7_accuracy: 0.9802 - dense_9_accuracy: 0.9856 - dense_11_accuracy: 0.9754 - val_loss: 0.3058 - val_dense_1_loss: 0.0489 - val_dense_3_loss: 0.0486 - val_dense_5_loss: 0.0489 - val_dense_7_loss: 0.0487 - val_dense_9_loss: 0.0486 - val_dense_11_loss: 0.0492 - val_dense_1_accuracy: 0.9930 - val_dense_3_accuracy: 0.9930 - val_dense_5_accuracy: 0.9930 - val_dense_7_accuracy: 0.9930 - val_dense_9_accuracy: 0.9930 - val_dense_11_accuracy: 0.9930\n",
      "Epoch 3/15\n",
      "3990/3990 [==============================] - 1829s 458ms/step - loss: 0.2967 - dense_1_loss: 0.0473 - dense_3_loss: 0.0473 - dense_5_loss: 0.0473 - dense_7_loss: 0.0473 - dense_9_loss: 0.0473 - dense_11_loss: 0.0472 - dense_1_accuracy: 0.9916 - dense_3_accuracy: 0.9902 - dense_5_accuracy: 0.9846 - dense_7_accuracy: 0.9924 - dense_9_accuracy: 0.9916 - dense_11_accuracy: 0.9901 - val_loss: 0.3003 - val_dense_1_loss: 0.0477 - val_dense_3_loss: 0.0480 - val_dense_5_loss: 0.0478 - val_dense_7_loss: 0.0479 - val_dense_9_loss: 0.0480 - val_dense_11_loss: 0.0476 - val_dense_1_accuracy: 0.9930 - val_dense_3_accuracy: 0.9930 - val_dense_5_accuracy: 0.9845 - val_dense_7_accuracy: 0.9930 - val_dense_9_accuracy: 0.9930 - val_dense_11_accuracy: 0.9930\n",
      "Epoch 4/15\n",
      "3990/3990 [==============================] - 1824s 457ms/step - loss: 0.2753 - dense_1_loss: 0.0437 - dense_3_loss: 0.0437 - dense_5_loss: 0.0436 - dense_7_loss: 0.0439 - dense_9_loss: 0.0437 - dense_11_loss: 0.0437 - dense_1_accuracy: 0.9855 - dense_3_accuracy: 0.9924 - dense_5_accuracy: 0.9863 - dense_7_accuracy: 0.9906 - dense_9_accuracy: 0.9927 - dense_11_accuracy: 0.9895 - val_loss: 0.2957 - val_dense_1_loss: 0.0472 - val_dense_3_loss: 0.0475 - val_dense_5_loss: 0.0473 - val_dense_7_loss: 0.0470 - val_dense_9_loss: 0.0473 - val_dense_11_loss: 0.0468 - val_dense_1_accuracy: 0.9930 - val_dense_3_accuracy: 0.9926 - val_dense_5_accuracy: 0.9757 - val_dense_7_accuracy: 0.9930 - val_dense_9_accuracy: 0.9930 - val_dense_11_accuracy: 0.9930\n",
      "Epoch 5/15\n",
      "3990/3990 [==============================] - 1794s 450ms/step - loss: 0.2539 - dense_1_loss: 0.0403 - dense_3_loss: 0.0402 - dense_5_loss: 0.0403 - dense_7_loss: 0.0403 - dense_9_loss: 0.0402 - dense_11_loss: 0.0404 - dense_1_accuracy: 0.9928 - dense_3_accuracy: 0.9936 - dense_5_accuracy: 0.9863 - dense_7_accuracy: 0.9914 - dense_9_accuracy: 0.9940 - dense_11_accuracy: 0.9928 - val_loss: 0.2996 - val_dense_1_loss: 0.0471 - val_dense_3_loss: 0.0482 - val_dense_5_loss: 0.0473 - val_dense_7_loss: 0.0478 - val_dense_9_loss: 0.0486 - val_dense_11_loss: 0.0473 - val_dense_1_accuracy: 0.9930 - val_dense_3_accuracy: 0.9929 - val_dense_5_accuracy: 0.9927 - val_dense_7_accuracy: 0.9930 - val_dense_9_accuracy: 0.9930 - val_dense_11_accuracy: 0.9930\n",
      "Epoch 6/15\n",
      "3990/3990 [==============================] - 1787s 448ms/step - loss: 0.2335 - dense_1_loss: 0.0369 - dense_3_loss: 0.0369 - dense_5_loss: 0.0369 - dense_7_loss: 0.0369 - dense_9_loss: 0.0370 - dense_11_loss: 0.0369 - dense_1_accuracy: 0.9866 - dense_3_accuracy: 0.9875 - dense_5_accuracy: 0.9829 - dense_7_accuracy: 0.9851 - dense_9_accuracy: 0.9917 - dense_11_accuracy: 0.9903 - val_loss: 0.3071 - val_dense_1_loss: 0.0491 - val_dense_3_loss: 0.0493 - val_dense_5_loss: 0.0490 - val_dense_7_loss: 0.0496 - val_dense_9_loss: 0.0489 - val_dense_11_loss: 0.0494 - val_dense_1_accuracy: 0.9930 - val_dense_3_accuracy: 0.9930 - val_dense_5_accuracy: 0.9930 - val_dense_7_accuracy: 0.9930 - val_dense_9_accuracy: 0.9930 - val_dense_11_accuracy: 0.9930\n",
      "Epoch 7/15\n",
      "3990/3990 [==============================] - 1785s 447ms/step - loss: 0.2134 - dense_1_loss: 0.0335 - dense_3_loss: 0.0337 - dense_5_loss: 0.0335 - dense_7_loss: 0.0335 - dense_9_loss: 0.0337 - dense_11_loss: 0.0337 - dense_1_accuracy: 0.9899 - dense_3_accuracy: 0.9917 - dense_5_accuracy: 0.9895 - dense_7_accuracy: 0.9839 - dense_9_accuracy: 0.9927 - dense_11_accuracy: 0.9892 - val_loss: 0.3121 - val_dense_1_loss: 0.0507 - val_dense_3_loss: 0.0497 - val_dense_5_loss: 0.0495 - val_dense_7_loss: 0.0516 - val_dense_9_loss: 0.0497 - val_dense_11_loss: 0.0496 - val_dense_1_accuracy: 0.9925 - val_dense_3_accuracy: 0.9924 - val_dense_5_accuracy: 0.9930 - val_dense_7_accuracy: 0.9922 - val_dense_9_accuracy: 0.9930 - val_dense_11_accuracy: 0.9930\n",
      "Epoch 8/15\n",
      "3990/3990 [==============================] - 1763s 442ms/step - loss: 0.1939 - dense_1_loss: 0.0303 - dense_3_loss: 0.0303 - dense_5_loss: 0.0304 - dense_7_loss: 0.0302 - dense_9_loss: 0.0304 - dense_11_loss: 0.0304 - dense_1_accuracy: 0.9838 - dense_3_accuracy: 0.9811 - dense_5_accuracy: 0.9758 - dense_7_accuracy: 0.9751 - dense_9_accuracy: 0.9841 - dense_11_accuracy: 0.9794 - val_loss: 0.3461 - val_dense_1_loss: 0.0541 - val_dense_3_loss: 0.0574 - val_dense_5_loss: 0.0571 - val_dense_7_loss: 0.0556 - val_dense_9_loss: 0.0542 - val_dense_11_loss: 0.0552 - val_dense_1_accuracy: 0.9924 - val_dense_3_accuracy: 0.9930 - val_dense_5_accuracy: 0.9928 - val_dense_7_accuracy: 0.9930 - val_dense_9_accuracy: 0.9930 - val_dense_11_accuracy: 0.9928\n",
      "Epoch 9/15\n",
      "3990/3990 [==============================] - 1747s 438ms/step - loss: 0.1764 - dense_1_loss: 0.0274 - dense_3_loss: 0.0272 - dense_5_loss: 0.0272 - dense_7_loss: 0.0273 - dense_9_loss: 0.0273 - dense_11_loss: 0.0274 - dense_1_accuracy: 0.9861 - dense_3_accuracy: 0.9688 - dense_5_accuracy: 0.9852 - dense_7_accuracy: 0.9879 - dense_9_accuracy: 0.9879 - dense_11_accuracy: 0.9860 - val_loss: 0.3529 - val_dense_1_loss: 0.0574 - val_dense_3_loss: 0.0573 - val_dense_5_loss: 0.0562 - val_dense_7_loss: 0.0567 - val_dense_9_loss: 0.0573 - val_dense_11_loss: 0.0567 - val_dense_1_accuracy: 0.9929 - val_dense_3_accuracy: 0.9930 - val_dense_5_accuracy: 0.9726 - val_dense_7_accuracy: 0.9930 - val_dense_9_accuracy: 0.9930 - val_dense_11_accuracy: 0.9930\n",
      "Epoch 10/15\n",
      "3990/3990 [==============================] - 1809s 453ms/step - loss: 0.1621 - dense_1_loss: 0.0248 - dense_3_loss: 0.0248 - dense_5_loss: 0.0248 - dense_7_loss: 0.0248 - dense_9_loss: 0.0249 - dense_11_loss: 0.0249 - dense_1_accuracy: 0.9769 - dense_3_accuracy: 0.9625 - dense_5_accuracy: 0.9823 - dense_7_accuracy: 0.9736 - dense_9_accuracy: 0.9889 - dense_11_accuracy: 0.9629 - val_loss: 0.3805 - val_dense_1_loss: 0.0609 - val_dense_3_loss: 0.0614 - val_dense_5_loss: 0.0605 - val_dense_7_loss: 0.0603 - val_dense_9_loss: 0.0620 - val_dense_11_loss: 0.0621 - val_dense_1_accuracy: 0.9830 - val_dense_3_accuracy: 0.9851 - val_dense_5_accuracy: 0.9841 - val_dense_7_accuracy: 0.9570 - val_dense_9_accuracy: 0.9913 - val_dense_11_accuracy: 0.8906\n",
      "Epoch 11/15\n",
      "3990/3990 [==============================] - 1779s 446ms/step - loss: 0.1567 - dense_1_loss: 0.0237 - dense_3_loss: 0.0239 - dense_5_loss: 0.0239 - dense_7_loss: 0.0239 - dense_9_loss: 0.0238 - dense_11_loss: 0.0239 - dense_1_accuracy: 0.9473 - dense_3_accuracy: 0.9610 - dense_5_accuracy: 0.9602 - dense_7_accuracy: 0.9225 - dense_9_accuracy: 0.9490 - dense_11_accuracy: 0.9398 - val_loss: 0.3958 - val_dense_1_loss: 0.0633 - val_dense_3_loss: 0.0637 - val_dense_5_loss: 0.0627 - val_dense_7_loss: 0.0643 - val_dense_9_loss: 0.0650 - val_dense_11_loss: 0.0637 - val_dense_1_accuracy: 0.9867 - val_dense_3_accuracy: 0.9919 - val_dense_5_accuracy: 0.9919 - val_dense_7_accuracy: 0.9718 - val_dense_9_accuracy: 0.9919 - val_dense_11_accuracy: 0.9926\n",
      "Epoch 12/15\n",
      "3990/3990 [==============================] - 1769s 443ms/step - loss: 0.1405 - dense_1_loss: 0.0212 - dense_3_loss: 0.0211 - dense_5_loss: 0.0211 - dense_7_loss: 0.0212 - dense_9_loss: 0.0212 - dense_11_loss: 0.0212 - dense_1_accuracy: 0.9330 - dense_3_accuracy: 0.9537 - dense_5_accuracy: 0.9341 - dense_7_accuracy: 0.8947 - dense_9_accuracy: 0.9572 - dense_11_accuracy: 0.9538 - val_loss: 0.4604 - val_dense_1_loss: 0.0767 - val_dense_3_loss: 0.0740 - val_dense_5_loss: 0.0723 - val_dense_7_loss: 0.0719 - val_dense_9_loss: 0.0722 - val_dense_11_loss: 0.0800 - val_dense_1_accuracy: 0.9871 - val_dense_3_accuracy: 0.9367 - val_dense_5_accuracy: 0.9883 - val_dense_7_accuracy: 0.9293 - val_dense_9_accuracy: 0.7572 - val_dense_11_accuracy: 0.9858\n",
      "Epoch 13/15\n",
      "3990/3990 [==============================] - 1780s 446ms/step - loss: 0.1322 - dense_1_loss: 0.0198 - dense_3_loss: 0.0197 - dense_5_loss: 0.0196 - dense_7_loss: 0.0197 - dense_9_loss: 0.0196 - dense_11_loss: 0.0197 - dense_1_accuracy: 0.9459 - dense_3_accuracy: 0.9156 - dense_5_accuracy: 0.9326 - dense_7_accuracy: 0.8230 - dense_9_accuracy: 0.9042 - dense_11_accuracy: 0.9174 - val_loss: 0.4810 - val_dense_1_loss: 0.0766 - val_dense_3_loss: 0.0763 - val_dense_5_loss: 0.0807 - val_dense_7_loss: 0.0785 - val_dense_9_loss: 0.0783 - val_dense_11_loss: 0.0757 - val_dense_1_accuracy: 0.9731 - val_dense_3_accuracy: 0.9742 - val_dense_5_accuracy: 0.9790 - val_dense_7_accuracy: 0.8521 - val_dense_9_accuracy: 0.9754 - val_dense_11_accuracy: 0.9706\n",
      "Epoch 14/15\n",
      "3990/3990 [==============================] - 1772s 444ms/step - loss: 0.1245 - dense_1_loss: 0.0183 - dense_3_loss: 0.0184 - dense_5_loss: 0.0182 - dense_7_loss: 0.0183 - dense_9_loss: 0.0183 - dense_11_loss: 0.0182 - dense_1_accuracy: 0.9070 - dense_3_accuracy: 0.8821 - dense_5_accuracy: 0.8823 - dense_7_accuracy: 0.7599 - dense_9_accuracy: 0.8546 - dense_11_accuracy: 0.8709 - val_loss: 0.4800 - val_dense_1_loss: 0.0785 - val_dense_3_loss: 0.0759 - val_dense_5_loss: 0.0781 - val_dense_7_loss: 0.0795 - val_dense_9_loss: 0.0754 - val_dense_11_loss: 0.0775 - val_dense_1_accuracy: 0.9734 - val_dense_3_accuracy: 0.9348 - val_dense_5_accuracy: 0.9014 - val_dense_7_accuracy: 0.9163 - val_dense_9_accuracy: 0.7708 - val_dense_11_accuracy: 0.9247\n",
      "Epoch 15/15\n",
      "3990/3990 [==============================] - 1795s 450ms/step - loss: 0.1172 - dense_1_loss: 0.0171 - dense_3_loss: 0.0173 - dense_5_loss: 0.0171 - dense_7_loss: 0.0171 - dense_9_loss: 0.0171 - dense_11_loss: 0.0171 - dense_1_accuracy: 0.8004 - dense_3_accuracy: 0.7987 - dense_5_accuracy: 0.8176 - dense_7_accuracy: 0.6629 - dense_9_accuracy: 0.8204 - dense_11_accuracy: 0.8230 - val_loss: 0.5383 - val_dense_1_loss: 0.0846 - val_dense_3_loss: 0.0848 - val_dense_5_loss: 0.0851 - val_dense_7_loss: 0.0878 - val_dense_9_loss: 0.0917 - val_dense_11_loss: 0.0896 - val_dense_1_accuracy: 0.9395 - val_dense_3_accuracy: 0.9118 - val_dense_5_accuracy: 0.9498 - val_dense_7_accuracy: 0.9172 - val_dense_9_accuracy: 0.8483 - val_dense_11_accuracy: 0.9161\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_padded, [train_data[columns] for column in columns], epochs=15, batch_size=32, validation_data=(val_padded, [val_data[columns] for column in columns]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T06:49:41.595930800Z",
     "start_time": "2023-12-01T23:23:31.938108400Z"
    }
   },
   "id": "1fc0dc3064fd3145"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499/499 [==============================] - 101s 199ms/step - loss: 1.5047 - dense_1_loss: 0.5452 - dense_3_loss: 0.1450 - dense_5_loss: 0.2356 - dense_7_loss: 0.1505 - dense_9_loss: 0.2505 - dense_11_loss: 0.1630 - dense_1_accuracy: 0.9434 - dense_3_accuracy: 0.9183 - dense_5_accuracy: 0.9548 - dense_7_accuracy: 0.9207 - dense_9_accuracy: 0.8506 - dense_11_accuracy: 0.9189\n",
      "loss: 1.5046818256378174\n",
      "dense_1_loss: 0.545199453830719\n",
      "dense_3_loss: 0.14503583312034607\n",
      "dense_5_loss: 0.23562633991241455\n",
      "dense_7_loss: 0.1505155861377716\n",
      "dense_9_loss: 0.2505280375480652\n",
      "dense_11_loss: 0.16302724182605743\n",
      "dense_1_accuracy: 0.9434139728546143\n",
      "dense_3_accuracy: 0.9183481931686401\n",
      "dense_5_accuracy: 0.9547562599182129\n",
      "dense_7_accuracy: 0.9206667542457581\n",
      "dense_9_accuracy: 0.8506078720092773\n",
      "dense_11_accuracy: 0.9189121723175049\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "results = model.evaluate(test_padded, [test_data[column] for column in columns])\n",
    "\n",
    "# Display the evaluation results\n",
    "for i, metric in enumerate(model.metrics_names):\n",
    "    print(f\"{metric}: {results[i]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T06:51:22.852290300Z",
     "start_time": "2023-12-02T06:49:41.604973900Z"
    }
   },
   "id": "d9e80381c5d62761"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "model.save('Comment_toxicity.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T07:40:09.592100300Z",
     "start_time": "2023-12-02T07:40:08.472012900Z"
    }
   },
   "id": "1e82d4b9db480a63"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "toxic: Confidence Level = 99.98%, Prediction = Positive\n",
      "severe_toxic: Confidence Level = 16.16%, Prediction = Negative\n",
      "obscene: Confidence Level = 99.96%, Prediction = Positive\n",
      "threat: Confidence Level = 0.00%, Prediction = Negative\n",
      "insult: Confidence Level = 99.03%, Prediction = Positive\n",
      "identity_hate: Confidence Level = 0.02%, Prediction = Negative\n",
      "Binary Predictions: [[1, 0, 1, 0, 1, 0]]\n"
     ]
    }
   ],
   "source": [
    "text = \"you fucking fool\" \n",
    "sequence = tokenizer.texts_to_sequences([text])\n",
    "padded_sequence = pad_sequences(sequence, maxlen=256, padding='post', truncating='post')\n",
    "predictions = model.predict(padded_sequence)\n",
    "\n",
    "\n",
    "# Display the predictions with confidence levels\n",
    "for i, column in enumerate(columns):\n",
    "    predicted_probabilities = predictions[i][0]  \n",
    "    target_class_index = i  \n",
    "    confidence_level = f\"{predicted_probabilities[target_class_index] * 100:.2f}%\"\n",
    "    prediction_label = \"Positive\" if predicted_probabilities[target_class_index] > 0.5 else \"Negative\"\n",
    "    print(f\"{column}: Confidence Level = {confidence_level}, Prediction = {prediction_label}\")\n",
    "\n",
    "\n",
    "binary_predictions = [[1 if prob[i] > 0.5 else 0 for i in range(len(columns))] for prob in predictions[0]]\n",
    "print(\"Binary Predictions:\", binary_predictions)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T06:51:25.846942Z",
     "start_time": "2023-12-02T06:51:23.578436500Z"
    }
   },
   "id": "64a78b91f6f7841d"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "toxic: Confidence Level = 0.00%, Prediction = Negative\n",
      "severe_toxic: Confidence Level = 0.00%, Prediction = Negative\n",
      "obscene: Confidence Level = 0.00%, Prediction = Negative\n",
      "threat: Confidence Level = 0.00%, Prediction = Negative\n",
      "insult: Confidence Level = 0.00%, Prediction = Negative\n",
      "identity_hate: Confidence Level = 0.00%, Prediction = Negative\n",
      "Binary Predictions: [[0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "text = \"I like talking about things that make me happy\" \n",
    "sequence = tokenizer.texts_to_sequences([text])\n",
    "padded_sequence = pad_sequences(sequence, maxlen=256, padding='post', truncating='post')\n",
    "predictions = model.predict(padded_sequence)\n",
    "\n",
    "\n",
    "# Display the predictions with confidence levels\n",
    "for i, column in enumerate(columns):\n",
    "    predicted_probabilities = predictions[i][0]  \n",
    "    target_class_index = i  \n",
    "    confidence_level = f\"{predicted_probabilities[target_class_index] * 100:.2f}%\"\n",
    "    prediction_label = \"Positive\" if predicted_probabilities[target_class_index] > 0.5 else \"Negative\"\n",
    "    print(f\"{column}: Confidence Level = {confidence_level}, Prediction = {prediction_label}\")\n",
    "\n",
    "\n",
    "binary_predictions = [[1 if prob[i] > 0.5 else 0 for i in range(len(columns))] for prob in predictions[0]]\n",
    "print(\"Binary Predictions:\", binary_predictions)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T06:51:25.974176700Z",
     "start_time": "2023-12-02T06:51:25.847938500Z"
    }
   },
   "id": "157e502f00ac9c1e"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n",
      "toxic: Confidence Level = 99.87%, Prediction = Positive\n",
      "severe_toxic: Confidence Level = 41.90%, Prediction = Negative\n",
      "obscene: Confidence Level = 94.10%, Prediction = Positive\n",
      "threat: Confidence Level = 89.01%, Prediction = Positive\n",
      "insult: Confidence Level = 73.40%, Prediction = Positive\n",
      "identity_hate: Confidence Level = 7.18%, Prediction = Negative\n",
      "Binary Predictions: [[1, 1, 1, 1, 1, 0]]\n"
     ]
    }
   ],
   "source": [
    "text = \"I will hurt and kill all your family members you worthless piece of shit\" \n",
    "sequence = tokenizer.texts_to_sequences([text])\n",
    "padded_sequence = pad_sequences(sequence, maxlen=256, padding='post', truncating='post')\n",
    "predictions = model.predict(padded_sequence)\n",
    "\n",
    "\n",
    "# Display the predictions with confidence levels\n",
    "for i, column in enumerate(columns):\n",
    "    predicted_probabilities = predictions[i][0]  \n",
    "    target_class_index = i  \n",
    "    confidence_level = f\"{predicted_probabilities[target_class_index] * 100:.2f}%\"\n",
    "    prediction_label = \"Positive\" if predicted_probabilities[target_class_index] > 0.5 else \"Negative\"\n",
    "    print(f\"{column}: Confidence Level = {confidence_level}, Prediction = {prediction_label}\")\n",
    "\n",
    "\n",
    "binary_predictions = [[1 if prob[i] > 0.5 else 0 for i in range(len(columns))] for prob in predictions[0]]\n",
    "print(\"Binary Predictions:\", binary_predictions)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T06:51:26.105901800Z",
     "start_time": "2023-12-02T06:51:25.977701500Z"
    }
   },
   "id": "848fd473818404ad"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n",
      "toxic: Confidence Level = 100.00%, Prediction = Positive\n",
      "severe_toxic: Confidence Level = 63.42%, Prediction = Positive\n",
      "obscene: Confidence Level = 99.64%, Prediction = Positive\n",
      "threat: Confidence Level = 91.54%, Prediction = Positive\n",
      "insult: Confidence Level = 84.16%, Prediction = Positive\n",
      "identity_hate: Confidence Level = 15.38%, Prediction = Negative\n",
      "Binary Predictions: [[1, 1, 1, 1, 1, 0]]\n"
     ]
    }
   ],
   "source": [
    "text = \"I hate you and your black ass, get the fuck out of here\" \n",
    "sequence = tokenizer.texts_to_sequences([text])\n",
    "padded_sequence = pad_sequences(sequence, maxlen=256, padding='post', truncating='post')\n",
    "predictions = model.predict(padded_sequence)\n",
    "\n",
    "\n",
    "# Display the predictions with confidence levels\n",
    "for i, column in enumerate(columns):\n",
    "    predicted_probabilities = predictions[i][0]  \n",
    "    target_class_index = i  \n",
    "    confidence_level = f\"{predicted_probabilities[target_class_index] * 100:.2f}%\"\n",
    "    prediction_label = \"Positive\" if predicted_probabilities[target_class_index] > 0.5 else \"Negative\"\n",
    "    print(f\"{column}: Confidence Level = {confidence_level}, Prediction = {prediction_label}\")\n",
    "\n",
    "\n",
    "binary_predictions = [[1 if prob[i] > 0.5 else 0 for i in range(len(columns))] for prob in predictions[0]]\n",
    "print(\"Binary Predictions:\", binary_predictions)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T07:04:21.147228900Z",
     "start_time": "2023-12-02T07:04:21.020365500Z"
    }
   },
   "id": "59b1880af3adaffd"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n",
      "toxic: Confidence Level = 0.24%, Prediction = Negative\n",
      "severe_toxic: Confidence Level = 0.01%, Prediction = Negative\n",
      "obscene: Confidence Level = 0.04%, Prediction = Negative\n",
      "threat: Confidence Level = 0.00%, Prediction = Negative\n",
      "insult: Confidence Level = 0.04%, Prediction = Negative\n",
      "identity_hate: Confidence Level = 0.01%, Prediction = Negative\n",
      "Binary Predictions: [[0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "text = \"I will find you and make you pay dearly for this, I suggest you run\" \n",
    "sequence = tokenizer.texts_to_sequences([text])\n",
    "padded_sequence = pad_sequences(sequence, maxlen=256, padding='post', truncating='post')\n",
    "predictions = model.predict(padded_sequence)\n",
    "\n",
    "\n",
    "# Display the predictions with confidence levels\n",
    "for i, column in enumerate(columns):\n",
    "    predicted_probabilities = predictions[i][0]  \n",
    "    target_class_index = i  \n",
    "    confidence_level = f\"{predicted_probabilities[target_class_index] * 100:.2f}%\"\n",
    "    prediction_label = \"Positive\" if predicted_probabilities[target_class_index] > 0.5 else \"Negative\"\n",
    "    print(f\"{column}: Confidence Level = {confidence_level}, Prediction = {prediction_label}\")\n",
    "\n",
    "\n",
    "binary_predictions = [[1 if prob[i] > 0.5 else 0 for i in range(len(columns))] for prob in predictions[0]]\n",
    "print(\"Binary Predictions:\", binary_predictions)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T07:07:38.226146Z",
     "start_time": "2023-12-02T07:07:38.061222600Z"
    }
   },
   "id": "d550d073b89149aa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
